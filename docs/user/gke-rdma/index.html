<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>GKE and GPUDirect RDMA with DRA | DraNet</title>
<meta name=description content='On Google Cloud A3 Ultra and A4 machine types, you can utilize GPUDirect RDMA to run distributed AI workloads that require high performance networking support. To get started, create a GKE cluster with DRA support and the corresponding VPC and subnets for the RDMA network for the A3Ultra or A4 Node Pools, the gcloud commands should be something like:
PROJECT="gke-dranet" CLUSTER="dranet-dranet" REGION="us-west8" ZONE="us-west8-c" GVNIC_NETWORK_PREFIX="dranet-gvnic" RDMA_NETWORK_PREFIX="dranet-rdma" VERSION="1.33" gcloud container clusters create "${CLUSTER}" \ --cluster-version="${VERSION}" \ --enable-multi-networking \ --enable-dataplane-v2 \ --enable-kubernetes-unstable-apis=resource.'><meta property="og:url" content="https://dranet.dev/docs/user/gke-rdma/"><meta property="og:site_name" content="DraNet"><meta property="og:title" content="GKE and GPUDirect RDMA with DRA"><meta property="og:description" content='On Google Cloud A3 Ultra and A4 machine types, you can utilize GPUDirect RDMA to run distributed AI workloads that require high performance networking support. To get started, create a GKE cluster with DRA support and the corresponding VPC and subnets for the RDMA network for the A3Ultra or A4 Node Pools, the gcloud commands should be something like:
PROJECT="gke-dranet" CLUSTER="dranet-dranet" REGION="us-west8" ZONE="us-west8-c" GVNIC_NETWORK_PREFIX="dranet-gvnic" RDMA_NETWORK_PREFIX="dranet-rdma" VERSION="1.33" gcloud container clusters create "${CLUSTER}" \ --cluster-version="${VERSION}" \ --enable-multi-networking \ --enable-dataplane-v2 \ --enable-kubernetes-unstable-apis=resource.'><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-05-27T11:30:40+00:00"><meta property="article:modified_time" content="2025-05-27T11:30:40+00:00"><meta itemprop=name content="GKE and GPUDirect RDMA with DRA"><meta itemprop=description content='On Google Cloud A3 Ultra and A4 machine types, you can utilize GPUDirect RDMA to run distributed AI workloads that require high performance networking support. To get started, create a GKE cluster with DRA support and the corresponding VPC and subnets for the RDMA network for the A3Ultra or A4 Node Pools, the gcloud commands should be something like:
PROJECT="gke-dranet" CLUSTER="dranet-dranet" REGION="us-west8" ZONE="us-west8-c" GVNIC_NETWORK_PREFIX="dranet-gvnic" RDMA_NETWORK_PREFIX="dranet-rdma" VERSION="1.33" gcloud container clusters create "${CLUSTER}" \ --cluster-version="${VERSION}" \ --enable-multi-networking \ --enable-dataplane-v2 \ --enable-kubernetes-unstable-apis=resource.'><meta itemprop=datePublished content="2025-05-27T11:30:40+00:00"><meta itemprop=dateModified content="2025-05-27T11:30:40+00:00"><meta itemprop=wordCount content="3510"><meta name=twitter:card content="summary"><meta name=twitter:title content="GKE and GPUDirect RDMA with DRA"><meta name=twitter:description content='On Google Cloud A3 Ultra and A4 machine types, you can utilize GPUDirect RDMA to run distributed AI workloads that require high performance networking support. To get started, create a GKE cluster with DRA support and the corresponding VPC and subnets for the RDMA network for the A3Ultra or A4 Node Pools, the gcloud commands should be something like:
PROJECT="gke-dranet" CLUSTER="dranet-dranet" REGION="us-west8" ZONE="us-west8-c" GVNIC_NETWORK_PREFIX="dranet-gvnic" RDMA_NETWORK_PREFIX="dranet-rdma" VERSION="1.33" gcloud container clusters create "${CLUSTER}" \ --cluster-version="${VERSION}" \ --enable-multi-networking \ --enable-dataplane-v2 \ --enable-kubernetes-unstable-apis=resource.'><link rel=preload href=/scss/main.min.3bb6570761fbbb25e6691001febc67f331f0953db4e4e1cfb79172c2e6a5819e.css as=style integrity="sha256-O7ZXB2H7uyXmaRAB/rxn8zHwlT205OHPt5FywualgZ4=" crossorigin=anonymous><link href=/scss/main.min.3bb6570761fbbb25e6691001febc67f331f0953db4e4e1cfb79172c2e6a5819e.css rel=stylesheet integrity="sha256-O7ZXB2H7uyXmaRAB/rxn8zHwlT205OHPt5FywualgZ4=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-YH3W884R6Z"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YH3W884R6Z")}</script></head><body class=td-page><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>DraNet</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/docs><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/docs/user><span>User Guides</span></a></li><li class=nav-item><a class=nav-link href=/docs/concepts><span>Concepts</span></a></li><li class=nav-item><a class=nav-link href=/docs/contributing><span>Contributing</span></a></li></ul></div><div class="d-none d-lg-block"><div class=td-search><div class=td-search__icon></div><input type=search class="td-search__input form-control td-search-input" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><div class=td-search><div class=td-search__icon></div><input type=search class="td-search__input form-control td-search-input" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off></div><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ms-3 fas fa-bars" type=button data-bs-toggle=collapse data-bs-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="td-sidebar-nav collapse" id=td-section-nav><ul class="td-sidebar-nav__section pe-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-docs-li><a href=/docs/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-docs><span>DraNet</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsquick-start-li><a href=/docs/quick-start/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsquick-start><span>Quick Start</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-docsuser-li><a href=/docs/user/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docsuser><span>User Guides</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsuserkuberay-li><a href=/docs/user/kuberay/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsuserkuberay><span>Ray on GKE using DraNet</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsusernvidia-dranet-li><a href=/docs/user/nvidia-dranet/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsusernvidia-dranet><span>GKE with NVIDIA DRA and DraNet</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsusergke-tpu-performance-li><a href=/docs/user/gke-tpu-performance/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsusergke-tpu-performance><span>GKE and Cloud TPU v6e (Trillium)</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-docsusergke-rdma-li><a href=/docs/user/gke-rdma/ class="align-left ps-0 active td-sidebar-link td-sidebar-link__page" id=m-docsusergke-rdma><span class=td-sidebar-nav-active-item>GKE and GPUDirect RDMA with DRA</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsusermpi-operator-li><a href=/docs/user/mpi-operator/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsusermpi-operator><span>MPI Operator on GKE and GPUDirect RDMA</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsuserinterface-configuration-li><a href=/docs/user/interface-configuration/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsuserinterface-configuration><span>Interface Configuration</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-docsconcepts-li><a href=/docs/concepts/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docsconcepts><span>Concepts</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsconceptslinux-network-interfaces-li><a href=/docs/concepts/linux-network-interfaces/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsconceptslinux-network-interfaces><span>Linux Network Namespaces and Interfaces</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsconceptsflexible-networks-li><a href=/docs/concepts/flexible-networks/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsconceptsflexible-networks><span>Making Networks Flexible</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsconceptsinterface-status-li><a href=/docs/concepts/interface-status/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsconceptsinterface-status><span>Interface Status</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsconceptshardware-efficiency-li><a href=/docs/concepts/hardware-efficiency/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsconceptshardware-efficiency><span>Hardware Efficiency</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsconceptsrdma-li><a href=/docs/concepts/rdma/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsconceptsrdma><span>RDMA</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsconceptsrdma-modes-li><a href=/docs/concepts/rdma-modes/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsconceptsrdma-modes><span>RDMA Device Handling</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsconceptshowitworks-li><a href=/docs/concepts/howitworks/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsconceptshowitworks><span>How It Works</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsconceptsreferences-li><a href=/docs/concepts/references/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsconceptsreferences><span>References</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-docscontributing-li><a href=/docs/contributing/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docscontributing><span>Contributing</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docscontributingdeveloper-guide-li><a href=/docs/contributing/developer-guide/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docscontributingdeveloper-guide><span>Developer Guide</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docscontributingcontributing-li><a href=/docs/contributing/contributing/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docscontributingcontributing><span>Contributing</span></a></li></ul></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ms-2 pb-1 pt-2 mb-0"><a href=https://github.com/google/dranet/tree/main/site/content/docs/user/gke-rdma.md class="td-page-meta--view td-page-meta__view" target=_blank rel=noopener><i class="fa-solid fa-file-lines fa-fw"></i> View page source</a>
<a href=https://github.com/google/dranet/edit/main/site/content/docs/user/gke-rdma.md class="td-page-meta--edit td-page-meta__edit" target=_blank rel=noopener><i class="fa-solid fa-pen-to-square fa-fw"></i> Edit this page</a>
<a href="https://github.com/google/dranet/new/main/site/content/docs/user?filename=change-me.md&amp;value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A" class="td-page-meta--child td-page-meta__child" target=_blank rel=noopener><i class="fa-solid fa-pen-to-square fa-fw"></i> Create child page</a>
<a href="https://github.com/google/dranet/issues/new?title=GKE%20and%20GPUDirect%20RDMA%20with%20DRA" class="td-page-meta--issue td-page-meta__issue" target=_blank rel=noopener><i class="fa-solid fa-list-check fa-fw"></i> Create documentation issue</a></div><div class=td-toc><nav id=TableOfContents><ul><li><ul><li></li></ul></li></ul></nav></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><nav aria-label=breadcrumb class=td-breadcrumbs><ol class=breadcrumb><li class=breadcrumb-item><a href=/docs/>DraNet</a></li><li class=breadcrumb-item><a href=/docs/user/>User Guides</a></li><li class="breadcrumb-item active" aria-current=page>GKE and GPUDirect RDMA with DRA</li></ol></nav><div class=td-content><h1>GKE and GPUDirect RDMA with DRA</h1><header class=article-meta></header><p>On Google Cloud A3 Ultra and A4 machine types, you can utilize GPUDirect RDMA to run distributed AI workloads that require high performance networking support. To get started, create a <a href=https://cloud.google.com/kubernetes-engine/docs/how-to/set-up-dra>GKE cluster with DRA support</a> and the corresponding <a href=https://cloud.google.com/ai-hypercomputer/docs/create/gke-ai-hypercompute-custom#create-vpcs-and-subnets>VPC and subnets</a> for the RDMA network for the A3Ultra or A4 Node Pools, the <code>gcloud</code> commands should be something like:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>PROJECT=<span style=color:#a31515>&#34;gke-dranet&#34;</span>
</span></span><span style=display:flex><span>CLUSTER=<span style=color:#a31515>&#34;dranet-dranet&#34;</span>
</span></span><span style=display:flex><span>REGION=<span style=color:#a31515>&#34;us-west8&#34;</span>
</span></span><span style=display:flex><span>ZONE=<span style=color:#a31515>&#34;us-west8-c&#34;</span>
</span></span><span style=display:flex><span>GVNIC_NETWORK_PREFIX=<span style=color:#a31515>&#34;dranet-gvnic&#34;</span>
</span></span><span style=display:flex><span>RDMA_NETWORK_PREFIX=<span style=color:#a31515>&#34;dranet-rdma&#34;</span>
</span></span><span style=display:flex><span>VERSION=<span style=color:#a31515>&#34;1.33&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gcloud container clusters create <span style=color:#a31515>&#34;</span><span style=color:#a31515>${</span>CLUSTER<span style=color:#a31515>}</span><span style=color:#a31515>&#34;</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --cluster-version=<span style=color:#a31515>&#34;</span><span style=color:#a31515>${</span>VERSION<span style=color:#a31515>}</span><span style=color:#a31515>&#34;</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --enable-multi-networking <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --enable-dataplane-v2 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --enable-kubernetes-unstable-apis=resource.k8s.io/v1beta1/deviceclasses,resource.k8s.io/v1beta1/resourceclaims,resource.k8s.io/v1beta1/resourceclaimtemplates,resource.k8s.io/v1beta1/resourceslices <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --no-enable-autorepair <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --no-enable-autoupgrade <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --zone=<span style=color:#a31515>&#34;</span><span style=color:#a31515>${</span>ZONE<span style=color:#a31515>}</span><span style=color:#a31515>&#34;</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --project=<span style=color:#a31515>&#34;</span><span style=color:#a31515>${</span>PROJECT<span style=color:#a31515>}</span><span style=color:#a31515>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># Create a VPC for the additional Google Titanium CPU NIC</span>
</span></span><span style=display:flex><span>gcloud compute --project=<span style=color:#a31515>${</span>PROJECT?<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  networks create <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  <span style=color:#a31515>${</span>GVNIC_NETWORK_PREFIX?<span style=color:#a31515>}</span>-net <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --subnet-mode=custom
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gcloud compute --project=<span style=color:#a31515>${</span>PROJECT?<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  networks subnets create <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  <span style=color:#a31515>${</span>GVNIC_NETWORK_PREFIX?<span style=color:#a31515>}</span>-sub <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --network=<span style=color:#a31515>${</span>GVNIC_NETWORK_PREFIX?<span style=color:#a31515>}</span>-net <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --region=<span style=color:#a31515>${</span>REGION?<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --range=192.168.0.0/24
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gcloud compute --project=<span style=color:#a31515>${</span>PROJECT?<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  firewall-rules create <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  <span style=color:#a31515>${</span>GVNIC_NETWORK_PREFIX?<span style=color:#a31515>}</span>-internal <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --network=<span style=color:#a31515>${</span>GVNIC_NETWORK_PREFIX?<span style=color:#a31515>}</span>-net <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --action=ALLOW <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --rules=tcp:0-65535,udp:0-65535,icmp <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --source-ranges=192.168.0.0/16
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># Create HPC VPC for the RDMA NICs with 8 subnets.</span>
</span></span><span style=display:flex><span>gcloudcompute --project=<span style=color:#a31515>${</span>PROJECT?<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  networks create <span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX?<span style=color:#a31515>}</span>-net <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --network-profile=<span style=color:#a31515>${</span>ZONE?<span style=color:#a31515>}</span>-vpc-roce <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --subnet-mode=custom
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># Create subnets for the HPC VPC.</span>
</span></span><span style=display:flex><span><span style=color:#00f>for</span> N in <span style=color:#00f>$(</span>seq 0 7<span style=color:#00f>)</span>; <span style=color:#00f>do</span>
</span></span><span style=display:flex><span>  gcloud compute --project=<span style=color:#a31515>${</span>PROJECT?<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    networks subnets create <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    <span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX?<span style=color:#a31515>}</span>-sub-$N <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --network=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX?<span style=color:#a31515>}</span>-net <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --region=<span style=color:#a31515>${</span>REGION?<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --range=192.168.<span style=color:#00f>$((</span>N+1<span style=color:#00f>))</span>.0/24 &amp;  <span style=color:green># offset to avoid overlap with gvnics</span>
</span></span><span style=display:flex><span><span style=color:#00f>done</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gcloud container node-pools create dranet-a4 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --cluster <span style=color:#a31515>${</span>CLUSTER<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --project <span style=color:#a31515>${</span>PROJECT<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --zone <span style=color:#a31515>${</span>ZONE<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --node-locations <span style=color:#a31515>${</span>ZONE<span style=color:#a31515>}</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --machine-type a4-highgpu-8g<span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --accelerator <span style=color:#a31515>&#34;type=nvidia-b200,count=8,gpu-driver-version=default&#34;</span> --num-nodes <span style=color:#a31515>&#34;2&#34;</span> <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --additional-node-network network=<span style=color:#a31515>${</span>GVNIC_NETWORK_PREFIX<span style=color:#a31515>}</span>-net,subnetwork=<span style=color:#a31515>${</span>GVNIC_NETWORK_PREFIX<span style=color:#a31515>}</span>-sub <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --additional-node-network network=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-net,subnetwork=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-sub-0 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --additional-node-network network=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-net,subnetwork=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-sub-1 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --additional-node-network network=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-net,subnetwork=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-sub-2 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --additional-node-network network=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-net,subnetwork=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-sub-3 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --additional-node-network network=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-net,subnetwork=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-sub-4 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --additional-node-network network=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-net,subnetwork=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-sub-5 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --additional-node-network network=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-net,subnetwork=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-sub-6 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>  --additional-node-network network=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-net,subnetwork=<span style=color:#a31515>${</span>RDMA_NETWORK_PREFIX<span style=color:#a31515>}</span>-sub-7
</span></span></code></pre></div><p>Apply the following DaemonSet to install the RDMA binaries and the NCCL library on the node. The RDMA binaries are stored in <code>/home/kubernetes/bin/gib</code> directory and the NCCL library is stored in <code>/home/kubernetes/bin/nvidia/lib64</code> directory on the VM:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/refs/heads/master/gpudirect-rdma/nccl-rdma-installer.yaml
</span></span></code></pre></div><p>Apply the following manifest to install DraNet:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/google/dranet/refs/heads/main/install.yaml
</span></span></code></pre></div><p>Once DraNet is running you&rsquo;ll be able to obtain the network resources exposed via the daemonsets, per example, this specific node has 8 RDMA nics as per the machine specification:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span> kubectl get resourceslices --field-selector spec.nodeName=gke-dra-1-gpu-nodes-2-e5f6f579-7je4 -o yaml | grep rdma
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span><span style=display:flex><span>            string: gpu0rdma0
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span><span style=display:flex><span>      name: gpu0rdma0
</span></span><span style=display:flex><span>            string: gpu1rdma0
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span><span style=display:flex><span>      name: gpu1rdma0
</span></span><span style=display:flex><span>            string: gpu2rdma0
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span><span style=display:flex><span>      name: gpu2rdma0
</span></span><span style=display:flex><span>            string: gpu3rdma0
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span><span style=display:flex><span>      name: gpu3rdma0
</span></span><span style=display:flex><span>            string: gpu4rdma0
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span><span style=display:flex><span>      name: gpu4rdma0
</span></span><span style=display:flex><span>            string: gpu5rdma0
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span><span style=display:flex><span>      name: gpu5rdma0
</span></span><span style=display:flex><span>            string: gpu6rdma0
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span><span style=display:flex><span>      name: gpu6rdma0
</span></span><span style=display:flex><span>            string: gpu7rdma0
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span><span style=display:flex><span>      name: gpu7rdma0
</span></span><span style=display:flex><span>          dra.net/rdma:
</span></span></code></pre></div><h4 id=defining-resources-for-dranet>Defining Resources for DraNet</h4><p>First, we tell DraNet what kind of NICs we&rsquo;re interested in and how Pods can claim them. In order to simplify our workloads we can create a <code>DeviceClass</code> that matches only the resources exposed by DraNet.</p><p><strong>DeviceClass (dranet):</strong> This selects NICs managed by DraNet.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: resource.k8s.io/v1beta1
</span></span><span style=display:flex><span>kind: DeviceClass
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: dranet
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  selectors:
</span></span><span style=display:flex><span>    - cel:
</span></span><span style=display:flex><span>        expression: device.driver == &#34;dra.net&#34;
</span></span></code></pre></div><p><strong>ResourceClaimTemplate (worker-rdma-nic-template):</strong> This will request 8 RDMA NICs.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: resource.k8s.io/v1beta1
</span></span><span style=display:flex><span>kind: ResourceClaimTemplate
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: rdma-net-template-gib
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  spec:
</span></span><span style=display:flex><span>    devices:
</span></span><span style=display:flex><span>      requests:
</span></span><span style=display:flex><span>      - name: rdma-net-interface
</span></span><span style=display:flex><span>        deviceClassName: dranet
</span></span><span style=display:flex><span>        count: 8
</span></span><span style=display:flex><span>        selectors:
</span></span><span style=display:flex><span>        - cel:
</span></span><span style=display:flex><span>            expression: device.attributes[&#34;dra.net&#34;].rdma == true
</span></span></code></pre></div><h4 id=creating-the-workload>Creating the workload</h4><p>We&rsquo;ll define a Statefulset with two workers, each getting the 8 GPUs and NICs from the VM. A headless Service will allow us to use DNS for autodiscovery.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Service
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: nccl-gib-test
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    name: nccl-gib-test
</span></span><span style=display:flex><span>  clusterIP: None
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: apps/v1
</span></span><span style=display:flex><span>kind: StatefulSet
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: nccl-gib-test
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    name: nccl-gib-test
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  replicas: 2
</span></span><span style=display:flex><span>  serviceName: nccl-gib-test
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      name: nccl-gib-test
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        name: nccl-gib-test
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      containers:
</span></span><span style=display:flex><span>      - image: us-docker.pkg.dev/gce-ai-infra/gpudirect-gib/nccl-plugin-gib-diagnostic:v1.0.6
</span></span><span style=display:flex><span>        name: test
</span></span><span style=display:flex><span>        securityContext:
</span></span><span style=display:flex><span>          capabilities:
</span></span><span style=display:flex><span>            add: [<span style=color:#a31515>&#34;IPC_LOCK&#34;</span>]
</span></span><span style=display:flex><span>        resources:
</span></span><span style=display:flex><span>          limits:
</span></span><span style=display:flex><span>            nvidia.com/gpu: 8
</span></span><span style=display:flex><span>        volumeMounts:
</span></span><span style=display:flex><span>          - name: library-dir-host
</span></span><span style=display:flex><span>            mountPath: /usr/local/nvidia
</span></span><span style=display:flex><span>          - name: gib
</span></span><span style=display:flex><span>            mountPath: /usr/local/gib
</span></span><span style=display:flex><span>          - name: shared-memory
</span></span><span style=display:flex><span>            mountPath: /dev/shm
</span></span><span style=display:flex><span>        env:
</span></span><span style=display:flex><span>          - name: LD_LIBRARY_PATH
</span></span><span style=display:flex><span>            value: /usr/local/nvidia/lib64
</span></span><span style=display:flex><span>        command: [<span style=color:#a31515>&#34;/bin/bash&#34;</span>, <span style=color:#a31515>&#34;-c&#34;</span>]
</span></span><span style=display:flex><span>        args:
</span></span><span style=display:flex><span>          - |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>            # we use a headless service to identify the workers that has the format &lt;hostname&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;
</span></span></span><span style=display:flex><span><span style=color:#a31515>            # hence we need to allow to resolve fqdn 
</span></span></span><span style=display:flex><span><span style=color:#a31515>            echo -e &#34;\norte_keep_fqdn_hostnames=t&#34; &gt;&gt; /etc/openmpi/openmpi-mca-params.conf
</span></span></span><span style=display:flex><span><span style=color:#a31515>            /scripts/container_entry.sh shell
</span></span></span><span style=display:flex><span><span style=color:#a31515>            source /usr/local/gib/scripts/set_nccl_env.sh
</span></span></span><span style=display:flex><span><span style=color:#a31515>            sleep infinity</span>            
</span></span><span style=display:flex><span>      volumes:
</span></span><span style=display:flex><span>        - name: library-dir-host
</span></span><span style=display:flex><span>          hostPath:
</span></span><span style=display:flex><span>            path: /home/kubernetes/bin/nvidia
</span></span><span style=display:flex><span>        - name: gib
</span></span><span style=display:flex><span>          hostPath:
</span></span><span style=display:flex><span>            path: /home/kubernetes/bin/gib
</span></span><span style=display:flex><span>        - name: shared-memory
</span></span><span style=display:flex><span>          emptyDir:
</span></span><span style=display:flex><span>            medium: <span style=color:#a31515>&#34;Memory&#34;</span>
</span></span><span style=display:flex><span>            sizeLimit: 250Gi
</span></span><span style=display:flex><span>      resourceClaims:
</span></span><span style=display:flex><span>      - name: rdma-net-interface
</span></span><span style=display:flex><span>        resourceClaimTemplateName: rdma-net-template-gib
</span></span></code></pre></div><h4 id=running-and-observing>Running and Observing</h4><p>Once deployed, we can see how the pods are scheduled</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl get pods
</span></span><span style=display:flex><span>NAME                                                               READY   STATUS      RESTARTS   AGE
</span></span><span style=display:flex><span>nccl-gib-test-0                                                    1/1     Running     0          6h35m
</span></span><span style=display:flex><span>nccl-gib-test-1                                                    1/1     Running     0          4h26m
</span></span></code></pre></div><p>and all the NICs are attached</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl get resourceclaims
</span></span><span style=display:flex><span>NAME                                       STATE                AGE
</span></span><span style=display:flex><span>nccl-gib-test-0-rdma-net-interface-mdsfv   allocated,reserved   6h37m
</span></span><span style=display:flex><span>nccl-gib-test-1-rdma-net-interface-t6jn8   allocated,reserved   4h28m
</span></span></code></pre></div><p>we can see all NICs on the node are connected to the Pod</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl get resourceclaim -o yaml
</span></span><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>items:
</span></span><span style=display:flex><span>- apiVersion: resource.k8s.io/v1beta1
</span></span><span style=display:flex><span>  kind: ResourceClaim
</span></span><span style=display:flex><span>  metadata:
</span></span><span style=display:flex><span>    annotations:
</span></span><span style=display:flex><span>      resource.kubernetes.io/pod-claim-name: rdma-net-interface
</span></span><span style=display:flex><span>    creationTimestamp: <span style=color:#a31515>&#34;2025-06-12T17:01:57Z&#34;</span>
</span></span><span style=display:flex><span>    finalizers:
</span></span><span style=display:flex><span>    - resource.kubernetes.io/delete-protection
</span></span><span style=display:flex><span>    generateName: nccl-gib-test-0-rdma-net-interface-
</span></span><span style=display:flex><span>    name: nccl-gib-test-0-rdma-net-interface-mdsfv
</span></span><span style=display:flex><span>    namespace: default
</span></span><span style=display:flex><span>    ownerReferences:
</span></span><span style=display:flex><span>    - apiVersion: v1
</span></span><span style=display:flex><span>      blockOwnerDeletion: true
</span></span><span style=display:flex><span>      controller: true
</span></span><span style=display:flex><span>      kind: Pod
</span></span><span style=display:flex><span>      name: nccl-gib-test-0
</span></span><span style=display:flex><span>      uid: 9af7b491-9342-412d-8fc2-0eedbc36a7b8
</span></span><span style=display:flex><span>    resourceVersion: <span style=color:#a31515>&#34;53060805&#34;</span>
</span></span><span style=display:flex><span>    uid: fda69ec2-9847-4f64-9540-432cba2489c7
</span></span><span style=display:flex><span>  spec:
</span></span><span style=display:flex><span>    devices:
</span></span><span style=display:flex><span>      requests:
</span></span><span style=display:flex><span>      - allocationMode: All
</span></span><span style=display:flex><span>        deviceClassName: dranet
</span></span><span style=display:flex><span>        name: rdma-net-interface
</span></span><span style=display:flex><span>        selectors:
</span></span><span style=display:flex><span>        - cel:
</span></span><span style=display:flex><span>            expression: device.attributes[<span style=color:#a31515>&#34;dra.net&#34;</span>].rdma == true
</span></span><span style=display:flex><span>  status:
</span></span><span style=display:flex><span>    allocation:
</span></span><span style=display:flex><span>      devices:
</span></span><span style=display:flex><span>        results:
</span></span><span style=display:flex><span>        - adminAccess: null
</span></span><span style=display:flex><span>          device: gpu0rdma0
</span></span><span style=display:flex><span>          driver: dra.net
</span></span><span style=display:flex><span>          pool: gke-dra-1-gpu-nodes-2-e5f6f579-7je4
</span></span><span style=display:flex><span>          request: rdma-net-interface
</span></span><span style=display:flex><span>        - adminAccess: null
</span></span><span style=display:flex><span>          device: gpu1rdma0
</span></span><span style=display:flex><span>          driver: dra.net
</span></span><span style=display:flex><span>          pool: gke-dra-1-gpu-nodes-2-e5f6f579-7je4
</span></span><span style=display:flex><span>          request: rdma-net-interface
</span></span><span style=display:flex><span>        - adminAccess: null
</span></span><span style=display:flex><span>          device: gpu2rdma0
</span></span><span style=display:flex><span>          driver: dra.net
</span></span><span style=display:flex><span>          pool: gke-dra-1-gpu-nodes-2-e5f6f579-7je4
</span></span><span style=display:flex><span>          request: rdma-net-interface
</span></span><span style=display:flex><span>        - adminAccess: null
</span></span><span style=display:flex><span>          device: gpu3rdma0
</span></span><span style=display:flex><span>          driver: dra.net
</span></span><span style=display:flex><span>          pool: gke-dra-1-gpu-nodes-2-e5f6f579-7je4
</span></span><span style=display:flex><span>          request: rdma-net-interface
</span></span><span style=display:flex><span>        - adminAccess: null
</span></span><span style=display:flex><span>          device: gpu4rdma0
</span></span><span style=display:flex><span>          driver: dra.net
</span></span><span style=display:flex><span>          pool: gke-dra-1-gpu-nodes-2-e5f6f579-7je4
</span></span><span style=display:flex><span>          request: rdma-net-interface
</span></span><span style=display:flex><span>        - adminAccess: null
</span></span><span style=display:flex><span>          device: gpu5rdma0
</span></span><span style=display:flex><span>          driver: dra.net
</span></span><span style=display:flex><span>          pool: gke-dra-1-gpu-nodes-2-e5f6f579-7je4
</span></span><span style=display:flex><span>          request: rdma-net-interface
</span></span><span style=display:flex><span>        - adminAccess: null
</span></span><span style=display:flex><span>          device: gpu6rdma0
</span></span><span style=display:flex><span>          driver: dra.net
</span></span><span style=display:flex><span>          pool: gke-dra-1-gpu-nodes-2-e5f6f579-7je4
</span></span><span style=display:flex><span>          request: rdma-net-interface
</span></span><span style=display:flex><span>        - adminAccess: null
</span></span><span style=display:flex><span>          device: gpu7rdma0
</span></span><span style=display:flex><span>          driver: dra.net
</span></span><span style=display:flex><span>          pool: gke-dra-1-gpu-nodes-2-e5f6f579-7je4
</span></span><span style=display:flex><span>          request: rdma-net-interface
</span></span></code></pre></div><p>To test the performance we will run the NCCL-tests, that are already installed in the existing workloads:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl exec -it nccl-gib-test-0 -- /usr/local/gib/scripts/run_nccl_tests.sh -t all_gather -b 1K -e 8G nccl-gib-test-0.nccl-gib-test nccl-gib-test-1.nccl-gib-test
</span></span><span style=display:flex><span>Initializing SSH...
</span></span><span style=display:flex><span>Warning: Permanently added <span style=color:#a31515>&#39;[nccl-gib-test-0.nccl-gib-test]:222&#39;</span> (ED25519) to the list of known hosts.
</span></span><span style=display:flex><span>Hello from nccl-gib-test-0.nccl-gib-test
</span></span><span style=display:flex><span>Hello from nccl-gib-test-1.nccl-gib-test
</span></span><span style=display:flex><span>Generating hostfiles <span style=color:#00f>for</span> 2 hosts:
</span></span><span style=display:flex><span>nccl-gib-test-0.nccl-gib-test
</span></span><span style=display:flex><span>nccl-gib-test-1.nccl-gib-test
</span></span><span style=display:flex><span><span style=color:green># nThread 1 nGpus 1 minBytes 1024 maxBytes 8589934592 step: 2(factor) warmup iters: 50 iters: 100 agg iters: 1 validation: 1 graph: 0</span>
</span></span><span style=display:flex><span><span style=color:green>#</span>
</span></span><span style=display:flex><span><span style=color:green># Using devices</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  0 Group  0 Pid  28616 on nccl-gib-test-0 device  0 [0000:8f:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  1 Group  0 Pid  28617 on nccl-gib-test-0 device  1 [0000:90:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  2 Group  0 Pid  28620 on nccl-gib-test-0 device  2 [0000:96:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  3 Group  0 Pid  28629 on nccl-gib-test-0 device  3 [0000:97:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  4 Group  0 Pid  28635 on nccl-gib-test-0 device  4 [0000:c4:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  5 Group  0 Pid  28644 on nccl-gib-test-0 device  5 [0000:c5:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  6 Group  0 Pid  28655 on nccl-gib-test-0 device  6 [0000:cb:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  7 Group  0 Pid  28667 on nccl-gib-test-0 device  7 [0000:cc:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  8 Group  0 Pid  22707 on nccl-gib-test-1 device  0 [0000:8f:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  9 Group  0 Pid  22708 on nccl-gib-test-1 device  1 [0000:90:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 10 Group  0 Pid  22711 on nccl-gib-test-1 device  2 [0000:96:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 11 Group  0 Pid  22720 on nccl-gib-test-1 device  3 [0000:97:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 12 Group  0 Pid  22727 on nccl-gib-test-1 device  4 [0000:c4:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 13 Group  0 Pid  22739 on nccl-gib-test-1 device  5 [0000:c5:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 14 Group  0 Pid  22749 on nccl-gib-test-1 device  6 [0000:cb:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 15 Group  0 Pid  22763 on nccl-gib-test-1 device  7 [0000:cc:00] NVIDIA B200</span>
</span></span><span style=display:flex><span>NCCL version 2.26.6+cuda12.8
</span></span><span style=display:flex><span><span style=color:green>#</span>
</span></span><span style=display:flex><span><span style=color:green>#                                                              out-of-place                       in-place</span>
</span></span><span style=display:flex><span><span style=color:green>#       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong</span>
</span></span><span style=display:flex><span><span style=color:green>#        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)</span>
</span></span><span style=display:flex><span>        1024            16     float    none      -1    280.4    0.00    0.00      0    233.9    0.00    0.00      0
</span></span><span style=display:flex><span>        2048            32     float    none      -1    268.2    0.01    0.01      0    303.2    0.01    0.01      0
</span></span><span style=display:flex><span>        4096            64     float    none      -1    317.7    0.01    0.01      0    292.7    0.01    0.01      0
</span></span><span style=display:flex><span>        8192           128     float    none      -1    320.0    0.03    0.02      0    274.0    0.03    0.03      0
</span></span><span style=display:flex><span>       16384           256     float    none      -1    290.3    0.06    0.05      0    283.4    0.06    0.05      0
</span></span><span style=display:flex><span>       32768           512     float    none      -1    246.2    0.13    0.12      0    328.1    0.10    0.09      0
</span></span><span style=display:flex><span>       65536          1024     float    none      -1    245.9    0.27    0.25      0    290.5    0.23    0.21      0
</span></span><span style=display:flex><span>      131072          2048     float    none      -1    287.1    0.46    0.43      0    281.7    0.47    0.44      0
</span></span><span style=display:flex><span>      262144          4096     float    none      -1    379.6    0.69    0.65      0    483.9    0.54    0.51      0
</span></span><span style=display:flex><span>      524288          8192     float    none      -1    549.9    0.95    0.89      0    575.9    0.91    0.85      0
</span></span><span style=display:flex><span>     1048576         16384     float    none      -1    998.2    1.05    0.98      0    972.4    1.08    1.01      0
</span></span><span style=display:flex><span>     2097152         32768     float    none      -1   1753.7    1.20    1.12      0   1557.5    1.35    1.26      0
</span></span><span style=display:flex><span>     4194304         65536     float    none      -1    933.6    4.49    4.21      0    958.6    4.38    4.10      0
</span></span><span style=display:flex><span>     8388608        131072     float    none      -1    981.2    8.55    8.02      0   1114.4    7.53    7.06      0
</span></span><span style=display:flex><span>    16777216        262144     float    none      -1   1479.0   11.34   10.63      0   1507.2   11.13   10.44      0
</span></span><span style=display:flex><span>    33554432        524288     float    none      -1   1240.7   27.05   25.36      0   1490.0   22.52   21.11      0
</span></span><span style=display:flex><span>    67108864       1048576     float    none      -1   1621.8   41.38   38.79      0   1524.0   44.03   41.28      0
</span></span><span style=display:flex><span>   134217728       2097152     float    none      -1   1877.8   71.48   67.01      0   1628.0   82.44   77.29      0
</span></span><span style=display:flex><span>   268435456       4194304     float    none      -1   3160.2   84.94   79.63      0   2993.9   89.66   84.06      0
</span></span><span style=display:flex><span>   536870912       8388608     float    none      -1   3332.1  161.12  151.05      0   3138.5  171.06  160.37      0
</span></span><span style=display:flex><span>  1073741824      16777216     float    none      -1   4057.5  264.63  248.09      0   4372.7  245.56  230.21      0
</span></span><span style=display:flex><span>  2147483648      33554432     float    none      -1   7753.4  276.97  259.66      0   7495.6  286.50  268.59      0
</span></span><span style=display:flex><span>  4294967296      67108864     float    none      -1    15394  279.00  261.57      0    15332  280.13  262.62      0
</span></span><span style=display:flex><span>  8589934592     134217728     float    none      -1    30970  277.36  260.03      0    31063  276.53  259.25      0
</span></span><span style=display:flex><span><span style=color:green># Out of bounds values : 0 OK</span>
</span></span><span style=display:flex><span><span style=color:green># Avg bus bandwidth    : 59.3638</span>
</span></span></code></pre></div><h4 id=running-a-workload-with-4-workers-4-gpus-and-4-nics-each-in-2-nodes>Running a Workload with 4 Workers, 4 GPUs, and 4 NICs Each in 2 Nodes</h4><p>While using fewer, larger instances (e.g., 2 workers with 8 GPUs/NICs) can simplify deployment, distributed AI workloads may benefit from a more granular approach, utilizing more workers with fewer resources each. This can lead to better resource utilization, increased parallelism, and improved fault tolerance. Here, we&rsquo;ll configure our workload to use 4 workers, with each worker claiming 4 GPUs and 4 corresponding DraNet-managed RDMA NICs.</p><p>For optimal performance in distributed AI, it&rsquo;s crucial to ensure the network interfaces are topologically closest to their associated GPUs. We can determine the host topology using <code>nvidia-smi topo -m</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>        GPU0    GPU1    GPU2    GPU3    GPU4    GPU5    GPU6    GPU7    NIC0    NIC1    NIC2    NIC3    NIC4    NIC5    NIC6    NIC7    CPU Affinity    NUMA Affinity      GPU NUMA ID
</span></span><span style=display:flex><span>GPU0     X      NV18    NV18    NV18    NV18    NV18    NV18    NV18    PIX     PIX     NODE    NODE    SYS     SYS     SYS     SYS     0-55,112-167    0 N/A
</span></span><span style=display:flex><span>GPU1    NV18     X      NV18    NV18    NV18    NV18    NV18    NV18    PIX     PIX     NODE    NODE    SYS     SYS     SYS     SYS     0-55,112-167    0 N/A
</span></span><span style=display:flex><span>GPU2    NV18    NV18     X      NV18    NV18    NV18    NV18    NV18    NODE    NODE    PIX     PIX     SYS     SYS     SYS     SYS     0-55,112-167    0 N/A
</span></span><span style=display:flex><span>GPU3    NV18    NV18    NV18     X      NV18    NV18    NV18    NV18    NODE    NODE    PIX     PIX     SYS     SYS     SYS     SYS     0-55,112-167    0 N/A
</span></span><span style=display:flex><span>GPU4    NV18    NV18    NV18    NV18     X      NV18    NV18    NV18    SYS     SYS     SYS     SYS     PIX     PIX     NODE    NODE    56-111,168-223  1 N/A
</span></span><span style=display:flex><span>GPU5    NV18    NV18    NV18    NV18    NV18     X      NV18    NV18    SYS     SYS     SYS     SYS     PIX     PIX     NODE    NODE    56-111,168-223  1 N/A
</span></span><span style=display:flex><span>GPU6    NV18    NV18    NV18    NV18    NV18    NV18     X      NV18    SYS     SYS     SYS     SYS     NODE    NODE    PIX     PIX     56-111,168-223  1 N/A
</span></span><span style=display:flex><span>GPU7    NV18    NV18    NV18    NV18    NV18    NV18    NV18     X      SYS     SYS     SYS     SYS     NODE    NODE    PIX     PIX     56-111,168-223  1 N/A
</span></span><span style=display:flex><span>NIC0    PIX     PIX     NODE    NODE    SYS     SYS     SYS     SYS      X      PIX     NODE    NODE    SYS     SYS     SYS     SYS
</span></span><span style=display:flex><span>NIC1    PIX     PIX     NODE    NODE    SYS     SYS     SYS     SYS     PIX      X      NODE    NODE    SYS     SYS     SYS     SYS
</span></span><span style=display:flex><span>NIC2    NODE    NODE    PIX     PIX     SYS     SYS     SYS     SYS     NODE    NODE     X      PIX     SYS     SYS     SYS     SYS
</span></span><span style=display:flex><span>NIC3    NODE    NODE    PIX     PIX     SYS     SYS     SYS     SYS     NODE    NODE    PIX      X      SYS     SYS     SYS     SYS
</span></span><span style=display:flex><span>NIC4    SYS     SYS     SYS     SYS     PIX     PIX     NODE    NODE    SYS     SYS     SYS     SYS      X      PIX     NODE    NODE
</span></span><span style=display:flex><span>NIC5    SYS     SYS     SYS     SYS     PIX     PIX     NODE    NODE    SYS     SYS     SYS     SYS     PIX      X      NODE    NODE
</span></span><span style=display:flex><span>NIC6    SYS     SYS     SYS     SYS     NODE    NODE    PIX     PIX     SYS     SYS     SYS     SYS     NODE    NODE     X      PIX
</span></span><span style=display:flex><span>NIC7    SYS     SYS     SYS     SYS     NODE    NODE    PIX     PIX     SYS     SYS     SYS     SYS     NODE    NODE    PIX      X
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Legend:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  X    = Self
</span></span><span style=display:flex><span>  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
</span></span><span style=display:flex><span>  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
</span></span><span style=display:flex><span>  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
</span></span><span style=display:flex><span>  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
</span></span><span style=display:flex><span>  PIX  = Connection traversing at most a single PCIe bridge
</span></span><span style=display:flex><span>  NV#  = Connection traversing a bonded set of <span style=color:green># NVLinks</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NIC Legend:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  NIC0: mlx5_0
</span></span><span style=display:flex><span>  NIC1: mlx5_1
</span></span><span style=display:flex><span>  NIC2: mlx5_2
</span></span><span style=display:flex><span>  NIC3: mlx5_3
</span></span><span style=display:flex><span>  NIC4: mlx5_4
</span></span><span style=display:flex><span>  NIC5: mlx5_5
</span></span><span style=display:flex><span>  NIC6: mlx5_6
</span></span><span style=display:flex><span>  NIC7: mlx5_7
</span></span></code></pre></div><p>To facilitate this configuration, we define a <code>ResourceClaimTemplate</code> that requests 4 RDMA NICs per worker. GKE A4 machines follow a naming convention where RDMA NICs are named <code>gpuXrdma0</code>, with X corresponding to the associated GPU index.</p><p>While a dedicated GPU DRA driver could leverage topological alignment using constraints and the standardized <code>resource.kubernetes.io/pcieRoot</code> attribute for optimal grouping (as discussed in <a href=https://github.com/NVIDIA/k8s-dra-driver-gpu/issues/213>NVIDIA/k8s-dra-driver-gpu#213</a>), just for this example and to show the flexibility of DraNet, we&rsquo;ll assume the GPU driver will implicitly provide the correct GPU device.</p><p>We are going to explicitly leverage the GKE naming convention to ensure each worker is allocated either the lower block of 4 NICs (gpu0-3rdma0) or the higher block of 4 NICs (gpu4-7rdma0). This selection logic is embedded directly within the selectors of our <code>ResourceClaimTemplate</code> using a CEL expression.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: resource.k8s.io/v1beta1
</span></span><span style=display:flex><span>kind: ResourceClaimTemplate
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: rdma-net-template-gib-flexible4nics
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  spec:
</span></span><span style=display:flex><span>    devices:
</span></span><span style=display:flex><span>      requests:
</span></span><span style=display:flex><span>      - name: rdma-net-interface
</span></span><span style=display:flex><span>        deviceClassName: dranet
</span></span><span style=display:flex><span>        count: 4 <span style=color:green># Requesting 4 NICs per worker</span>
</span></span><span style=display:flex><span>        selectors:
</span></span><span style=display:flex><span>        - cel:
</span></span><span style=display:flex><span>            expression: |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>              device.attributes[&#34;dra.net&#34;].rdma == true &amp;&amp;
</span></span></span><span style=display:flex><span><span style=color:#a31515>              (
</span></span></span><span style=display:flex><span><span style=color:#a31515>                (device.attributes[&#34;dra.net&#34;].ifName.startsWith(&#34;gpu&#34;) &amp;&amp;
</span></span></span><span style=display:flex><span><span style=color:#a31515>                 device.attributes[&#34;dra.net&#34;].ifName.endsWith(&#34;rdma0&#34;) &amp;&amp;
</span></span></span><span style=display:flex><span><span style=color:#a31515>                 int(device.attributes[&#34;dra.net&#34;].ifName.substring(3, 4)) &lt; 4)
</span></span></span><span style=display:flex><span><span style=color:#a31515>              ||
</span></span></span><span style=display:flex><span><span style=color:#a31515>                (device.attributes[&#34;dra.net&#34;].ifName.startsWith(&#34;gpu&#34;) &amp;&amp;
</span></span></span><span style=display:flex><span><span style=color:#a31515>                 device.attributes[&#34;dra.net&#34;].ifName.endsWith(&#34;rdma0&#34;) &amp;&amp;
</span></span></span><span style=display:flex><span><span style=color:#a31515>                 int(device.attributes[&#34;dra.net&#34;].ifName.substring(3, 4)) &gt;= 4)
</span></span></span><span style=display:flex><span><span style=color:#a31515>              )</span>              
</span></span></code></pre></div><p>We&rsquo;ll define a StatefulSet with four replicas, each configured to receive 4 GPUs and the 4 requested RDMA NICs.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Service
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: nccl-gib-test-4w
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    name: nccl-gib-test-4w
</span></span><span style=display:flex><span>  clusterIP: None
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: apps/v1
</span></span><span style=display:flex><span>kind: StatefulSet
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: nccl-gib-test-4w
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    name: nccl-gib-test-4w
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  replicas: 4
</span></span><span style=display:flex><span>  serviceName: nccl-gib-test-4w
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      name: nccl-gib-test-4w
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        name: nccl-gib-test-4w
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      containers:
</span></span><span style=display:flex><span>      - image: us-docker.pkg.dev/gce-ai-infra/gpudirect-gib/nccl-plugin-gib-diagnostic:v1.0.6
</span></span><span style=display:flex><span>        name: test
</span></span><span style=display:flex><span>        securityContext:
</span></span><span style=display:flex><span>          capabilities:
</span></span><span style=display:flex><span>            add: [<span style=color:#a31515>&#34;IPC_LOCK&#34;</span>]
</span></span><span style=display:flex><span>        resources:
</span></span><span style=display:flex><span>          limits:
</span></span><span style=display:flex><span>            nvidia.com/gpu: 4
</span></span><span style=display:flex><span>        volumeMounts:
</span></span><span style=display:flex><span>          - name: library-dir-host
</span></span><span style=display:flex><span>            mountPath: /usr/local/nvidia
</span></span><span style=display:flex><span>          - name: gib
</span></span><span style=display:flex><span>            mountPath: /usr/local/gib
</span></span><span style=display:flex><span>          - name: shared-memory
</span></span><span style=display:flex><span>            mountPath: /dev/shm
</span></span><span style=display:flex><span>        env:
</span></span><span style=display:flex><span>          - name: LD_LIBRARY_PATH
</span></span><span style=display:flex><span>            value: /usr/local/nvidia/lib64
</span></span><span style=display:flex><span>        command: [<span style=color:#a31515>&#34;/bin/bash&#34;</span>, <span style=color:#a31515>&#34;-c&#34;</span>]
</span></span><span style=display:flex><span>        args:
</span></span><span style=display:flex><span>          - |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>            # we use a headless service to identify the workers that has the format &lt;hostname&gt;.&lt;service&gt;.&lt;ns&gt;.svc.&lt;zone&gt;
</span></span></span><span style=display:flex><span><span style=color:#a31515>            # hence we need to allow to resolve fqdn 
</span></span></span><span style=display:flex><span><span style=color:#a31515>            echo -e &#34;\norte_keep_fqdn_hostnames=t&#34; &gt;&gt; /etc/openmpi/openmpi-mca-params.conf
</span></span></span><span style=display:flex><span><span style=color:#a31515>            /scripts/container_entry.sh shell
</span></span></span><span style=display:flex><span><span style=color:#a31515>            source /usr/local/gib/scripts/set_nccl_env.sh
</span></span></span><span style=display:flex><span><span style=color:#a31515>            sleep infinity</span>            
</span></span><span style=display:flex><span>      volumes:
</span></span><span style=display:flex><span>        - name: library-dir-host
</span></span><span style=display:flex><span>          hostPath:
</span></span><span style=display:flex><span>            path: /home/kubernetes/bin/nvidia
</span></span><span style=display:flex><span>        - name: gib
</span></span><span style=display:flex><span>          hostPath:
</span></span><span style=display:flex><span>            path: /home/kubernetes/bin/gib
</span></span><span style=display:flex><span>        - name: shared-memory
</span></span><span style=display:flex><span>          emptyDir:
</span></span><span style=display:flex><span>            medium: <span style=color:#a31515>&#34;Memory&#34;</span>
</span></span><span style=display:flex><span>            sizeLimit: 125Gi
</span></span><span style=display:flex><span>      resourceClaims:
</span></span><span style=display:flex><span>      - name: rdma-net-interface
</span></span><span style=display:flex><span>        resourceClaimTemplateName: rdma-net-template-gib-flexible4nics
</span></span></code></pre></div><p>The pods will be scheduled with the corresponding interfaces:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl get pods -o wide
</span></span><span style=display:flex><span>NAME                 READY   STATUS    RESTARTS   AGE     IP          NODE                                                  NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>nccl-gib-test-4w-0   1/1     Running   0          2m51s   10.68.5.7   gke-dranet-maspinwal-dranet-maspinwal-d3003787-lp53   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>nccl-gib-test-4w-1   1/1     Running   0          109s    10.68.3.7   gke-dranet-maspinwal-dranet-maspinwal-d3003787-zwtv   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>nccl-gib-test-4w-2   1/1     Running   0          51s     10.68.5.8   gke-dranet-maspinwal-dranet-maspinwal-d3003787-lp53   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>nccl-gib-test-4w-3   1/1     Running   0          48s     10.68.3.8   gke-dranet-maspinwal-dranet-maspinwal-d3003787-zwtv   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div><p>And we can confirm that each Pod gets either the lower or higher block of NICs:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl exec -it nccl-gib-test-4w-0  -- ip a
</span></span><span style=display:flex><span>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
</span></span><span style=display:flex><span>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span style=display:flex><span>    inet 127.0.0.1/8 scope host lo
</span></span><span style=display:flex><span>       valid_lft forever preferred_lft forever
</span></span><span style=display:flex><span>2: eth0@if20: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1460 qdisc noqueue state UP group default qlen 1000
</span></span><span style=display:flex><span>    link/ether 8e:ea:cf:24:93:50 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span><span style=display:flex><span>    inet 10.68.5.7/24 brd 10.68.5.255 scope global eth0
</span></span><span style=display:flex><span>       valid_lft forever preferred_lft forever
</span></span><span style=display:flex><span>4: gpu0rdma0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8896 qdisc mq state UP group default qlen 1000
</span></span><span style=display:flex><span>    link/ether 7e:75:3c:80:88:01 brd ff:ff:ff:ff:ff:ff
</span></span><span style=display:flex><span>    inet 192.168.1.4/32 scope global gpu0rdma0
</span></span><span style=display:flex><span>       valid_lft forever preferred_lft forever
</span></span><span style=display:flex><span>5: gpu1rdma0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8896 qdisc mq state UP group default qlen 1000
</span></span><span style=display:flex><span>    link/ether ca:18:5a:64:f9:04 brd ff:ff:ff:ff:ff:ff
</span></span><span style=display:flex><span>    inet 192.168.2.4/32 scope global gpu1rdma0
</span></span><span style=display:flex><span>       valid_lft forever preferred_lft forever
</span></span><span style=display:flex><span>6: gpu2rdma0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8896 qdisc mq state UP group default qlen 1000
</span></span><span style=display:flex><span>    link/ether d2:c2:50:6e:7c:07 brd ff:ff:ff:ff:ff:ff
</span></span><span style=display:flex><span>    inet 192.168.3.4/32 scope global gpu2rdma0
</span></span><span style=display:flex><span>       valid_lft forever preferred_lft forever
</span></span><span style=display:flex><span>7: gpu3rdma0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8896 qdisc mq state UP group default qlen 1000
</span></span><span style=display:flex><span>    link/ether 02:8a:b8:7e:0a:0a brd ff:ff:ff:ff:ff:ff
</span></span><span style=display:flex><span>    inet 192.168.4.4/32 scope global gpu3rdma0
</span></span><span style=display:flex><span>       valid_lft forever preferred_lft forever
</span></span></code></pre></div><p>Now lets&rsquo;s run the NCCL-tests on this new 4 worker configuration:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl exec -it nccl-gib-test-4w-0 -- /usr/local/gib/scripts/run_nccl_tests.sh -t all_gather -b 1K -g 4 -e 8G nccl-gib-test-4w-0.nccl-gib-test-4w nccl-gib-test-4w-1.nccl-gib-test-4w nccl-gib-test-4w-2.nccl-gib-test-4w nccl-gib-test-4w-3.nccl-gib-test-4w
</span></span><span style=display:flex><span>Initializing SSH...
</span></span><span style=display:flex><span>Hello from nccl-gib-test-4w-0.nccl-gib-test-4w
</span></span><span style=display:flex><span>Hello from nccl-gib-test-4w-1.nccl-gib-test-4w
</span></span><span style=display:flex><span>Hello from nccl-gib-test-4w-2.nccl-gib-test-4w
</span></span><span style=display:flex><span>Hello from nccl-gib-test-4w-3.nccl-gib-test-4w
</span></span><span style=display:flex><span>Generating hostfiles <span style=color:#00f>for</span> 4 hosts:
</span></span><span style=display:flex><span>nccl-gib-test-4w-0.nccl-gib-test-4w
</span></span><span style=display:flex><span>nccl-gib-test-4w-1.nccl-gib-test-4w
</span></span><span style=display:flex><span>nccl-gib-test-4w-2.nccl-gib-test-4w
</span></span><span style=display:flex><span>nccl-gib-test-4w-3.nccl-gib-test-4w
</span></span><span style=display:flex><span><span style=color:green># nThread 1 nGpus 1 minBytes 1024 maxBytes 8589934592 step: 2(factor) warmup iters: 50 iters: 100 agg iters: 1 validation: 1 graph: 0</span>
</span></span><span style=display:flex><span><span style=color:green>#</span>
</span></span><span style=display:flex><span><span style=color:green># Using devices</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  0 Group  0 Pid  19517 on nccl-gib-test-4w-0 device  0 [0000:8f:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  1 Group  0 Pid  19514 on nccl-gib-test-4w-0 device  1 [0000:90:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  2 Group  0 Pid  19523 on nccl-gib-test-4w-0 device  2 [0000:cb:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  3 Group  0 Pid  19534 on nccl-gib-test-4w-0 device  3 [0000:cc:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  4 Group  0 Pid  19353 on nccl-gib-test-4w-1 device  0 [0000:8f:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  5 Group  0 Pid  19374 on nccl-gib-test-4w-1 device  1 [0000:90:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  6 Group  0 Pid  19383 on nccl-gib-test-4w-1 device  2 [0000:96:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  7 Group  0 Pid  19399 on nccl-gib-test-4w-1 device  3 [0000:cc:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  8 Group  0 Pid  19345 on nccl-gib-test-4w-2 device  0 [0000:96:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  9 Group  0 Pid  19387 on nccl-gib-test-4w-2 device  1 [0000:97:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 10 Group  0 Pid  19379 on nccl-gib-test-4w-2 device  2 [0000:c4:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 11 Group  0 Pid  19398 on nccl-gib-test-4w-2 device  3 [0000:c5:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 12 Group  0 Pid  19383 on nccl-gib-test-4w-3 device  0 [0000:97:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 13 Group  0 Pid  19347 on nccl-gib-test-4w-3 device  1 [0000:c4:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 14 Group  0 Pid  19390 on nccl-gib-test-4w-3 device  2 [0000:c5:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 15 Group  0 Pid  19396 on nccl-gib-test-4w-3 device  3 [0000:cb:00] NVIDIA B200</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># ... (truncated NCCL output for brevity) ...</span>
</span></span><span style=display:flex><span><span style=color:green># Out of bounds values : 0 OK</span>
</span></span><span style=display:flex><span><span style=color:green># Avg bus bandwidth    : 22.2173</span>
</span></span><span style=display:flex><span><span style=color:green>#</span>
</span></span></code></pre></div><p>This is just an illustrative example, there is no GPU and NIC alignment. Also, for collective operations like <code>all_gather</code> that benefit immensely from high-bandwidth, low-latency intra-node communication (like NVLink) in this case, consolidating more GPUs into fewer workers (i.e., making each worker span an entire physical node&rsquo;s GPU complement) results in significantly better performance. The 2-worker (8 GPUs/worker) configuration achieved much higher <code>all_gather</code> bandwidth compared to the 4-worker (4 GPUs/worker) configuration, despite both using the same total number of GPUs across the same two physical nodes.</p><p>To highlight the importance of topological alignment, we compare the previous results with a scenario where the GPUs and NICs are even more misaligned , the same <code>all_gather</code> test with 4 pods setup gives half of the performance than before.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span> kubectl exec -it nccl-gib-test-4w-0 -- /usr/local/gib/scripts/run_nccl_tests.sh -t all_gather -b 1K -g 4 -e 8G nccl-gib-test-4w-0.nccl-gib-test-4w nccl-gib-test-4w-1.nccl-gib-test-4w nccl-gib-test-4w-2.nccl-gib-test-4w nccl-gib-test-4w-3.nccl-gib-test-4w
</span></span><span style=display:flex><span>Initializing SSH...
</span></span><span style=display:flex><span>Warning: Permanently added <span style=color:#a31515>&#39;[nccl-gib-test-4w-0.nccl-gib-test-4w]:222,[10.68.3.18]:222&#39;</span> (ECDSA) to the list of known hosts.
</span></span><span style=display:flex><span>Hello from nccl-gib-test-4w-0.nccl-gib-test-4w
</span></span><span style=display:flex><span>Warning: Permanently added <span style=color:#a31515>&#39;[nccl-gib-test-4w-1.nccl-gib-test-4w]:222,[10.68.3.19]:222&#39;</span> (ECDSA) to the list of known hosts.
</span></span><span style=display:flex><span>Hello from nccl-gib-test-4w-1.nccl-gib-test-4w
</span></span><span style=display:flex><span>Warning: Permanently added <span style=color:#a31515>&#39;[nccl-gib-test-4w-2.nccl-gib-test-4w]:222,[10.68.5.18]:222&#39;</span> (ECDSA) to the list of known hosts.
</span></span><span style=display:flex><span>Hello from nccl-gib-test-4w-2.nccl-gib-test-4w
</span></span><span style=display:flex><span>Warning: Permanently added <span style=color:#a31515>&#39;[nccl-gib-test-4w-3.nccl-gib-test-4w]:222,[10.68.5.19]:222&#39;</span> (ECDSA) to the list of known hosts.
</span></span><span style=display:flex><span>Hello from nccl-gib-test-4w-3.nccl-gib-test-4w
</span></span><span style=display:flex><span>Generating hostfiles <span style=color:#00f>for</span> 4 hosts:
</span></span><span style=display:flex><span>nccl-gib-test-4w-0.nccl-gib-test-4w
</span></span><span style=display:flex><span>nccl-gib-test-4w-1.nccl-gib-test-4w
</span></span><span style=display:flex><span>nccl-gib-test-4w-2.nccl-gib-test-4w
</span></span><span style=display:flex><span>nccl-gib-test-4w-3.nccl-gib-test-4w
</span></span><span style=display:flex><span><span style=color:green># nThread 1 nGpus 1 minBytes 1024 maxBytes 8589934592 step: 2(factor) warmup iters: 50 iters: 100 agg iters: 1 validation: 1 graph: 0</span>
</span></span><span style=display:flex><span><span style=color:green>#</span>
</span></span><span style=display:flex><span><span style=color:green># Using devices</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  0 Group  0 Pid   3351 on nccl-gib-test-4w-0 device  0 [0000:97:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  1 Group  0 Pid   3366 on nccl-gib-test-4w-0 device  1 [0000:c4:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  2 Group  0 Pid   3392 on nccl-gib-test-4w-0 device  2 [0000:c5:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  3 Group  0 Pid   3393 on nccl-gib-test-4w-0 device  3 [0000:cb:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  4 Group  0 Pid   3317 on nccl-gib-test-4w-1 device  0 [0000:8f:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  5 Group  0 Pid   3350 on nccl-gib-test-4w-1 device  1 [0000:90:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  6 Group  0 Pid   3349 on nccl-gib-test-4w-1 device  2 [0000:96:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  7 Group  0 Pid   3358 on nccl-gib-test-4w-1 device  3 [0000:cc:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  8 Group  0 Pid   3321 on nccl-gib-test-4w-2 device  0 [0000:8f:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank  9 Group  0 Pid   3359 on nccl-gib-test-4w-2 device  1 [0000:c5:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 10 Group  0 Pid   3358 on nccl-gib-test-4w-2 device  2 [0000:cb:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 11 Group  0 Pid   3335 on nccl-gib-test-4w-2 device  3 [0000:cc:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 12 Group  0 Pid   3316 on nccl-gib-test-4w-3 device  0 [0000:90:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 13 Group  0 Pid   3355 on nccl-gib-test-4w-3 device  1 [0000:96:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 14 Group  0 Pid   3359 on nccl-gib-test-4w-3 device  2 [0000:97:00] NVIDIA B200</span>
</span></span><span style=display:flex><span><span style=color:green>#  Rank 15 Group  0 Pid   3341 on nccl-gib-test-4w-3 device  3 [0000:c4:00] NVIDIA B200</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># ... (truncated NCCL output for brevity) ...</span>
</span></span><span style=display:flex><span><span style=color:green># Out of bounds values : 0 OK</span>
</span></span><span style=display:flex><span><span style=color:green># Avg bus bandwidth    : 11.2291</span>
</span></span><span style=display:flex><span><span style=color:green>#</span>
</span></span></code></pre></div><h4 id=troubleshooting-notes>Troubleshooting Notes</h4><p>If you encounter network failures during testing, indicated by errors such as:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>nccl-gib-test-4w-3: Test CUDA failure common.cu:1030 <span style=color:#a31515>&#39;invalid device ordinal&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>nccl-gib-test-4w-1: transport/nvls.cc:598 NCCL WARN Cuda failure 1 <span style=color:#a31515>&#39;invalid argument&#39;</span>
</span></span></code></pre></div><p>A common resolution is to reboot the affected virtual machines.</p><p><strong>References</strong>:</p><p><a href=https://github.com/NVIDIA/nccl/issues/1672>https://github.com/NVIDIA/nccl/issues/1672</a></p><p><a href=https://github.com/NVIDIA/nccl/issues/1562>https://github.com/NVIDIA/nccl/issues/1562</a></p></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title="SIG Network mailing list" aria-label="SIG Network mailing list"><a target=_blank rel=noopener href=https://groups.google.com/forum/#!forum/kubernetes-sig-network aria-label="SIG Network mailing list"><i class="fa fa-envelope"></i></a></li></ul></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/google/dranet aria-label=GitHub><i class="fab fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Slack aria-label=Slack><a target=_blank rel=noopener href=https://kubernetes.slack.com/messages/sig-network aria-label=Slack><i class="fab fa-slack"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2024&ndash;2025
<span class=td-footer__authors>Google LLC | <a href=https://creativecommons.org/licenses/by/4.0>CC BY 4.0</a> |</span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span><span class=ms-2><a href=https://policies.google.com/privacy target=_blank rel=noopener>Privacy Policy</a></span></div></div></div></footer></div><script src=/js/main.min.d9615597e83c4193e3ab1e6816bad5c8741894e92c5b5c17a8d1d4be6d9af8a2.js integrity="sha256-2WFVl+g8QZPjqx5oFrrVyHQYlOksW1wXqNHUvm2a+KI=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>